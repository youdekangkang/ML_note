### 标准构建方式

Pytorch构建数据集的标准方式如下：

```python
class CustomDataset(Dataset): # from torch.utils.data import Dataset
    def __init__(self):
        # TODO
        # 1. Initialize file path or list of file names.
        pass
    def __getitem__(self, index):
        # TODO
        # 1. Read one data from file (e.g. using numpy.fromfile, PIL.Image.open).
        # 2. Preprocess the data (e.g. torchvision.Transform).
        # 3. Return a data pair (e.g. image and label).
        pass
    def __len__(self):
        # You should change 0 to the total size of your dataset.
        return 0
```

其中在`__init__`中完成类的继承和变量的定义，在`__getitem__`中完成对于某个index的样本的处理，并且返回该样本及其标签，在`__len__`中返回样本总量。在此，我们利用之前定义好的`train_df`、`valid_df`和`sub_df`完成数据集的构建。





### 范例

在Atlas比赛中，构建的数据集不是常规的RGB模式，首先需要进行一定的预处理

```python
class AtlasDataset(Dataset):
    def __init__(self, df, path, size=None, label=True):        
        self.df = df.copy()
        self.path = path
        self.size = size
        self.label = label
        #把标签集中的数字换成对应的名称
        if self.label:
            self.df['Target'] = [[int(i) for i in s.split()] for s in self.df['Target']] # 对标签进行预处理
        
    def __getitem__(self, index):        
        img = open_rgby(self.path, self.df['Id'].iloc[index], self.size)
        if self.label:
            target = np.eye(N_CLASSES,dtype=np.float)[self.df['Target'].iloc[index]].sum(axis=0) # 对标签进行独热编码
        else:
            target = np.zeros(N_CLASSES,dtype=np.int)
        return img, target
    
    def __len__(self):
        return len(self.df)
```

定义好Dateset后，可以使用`torch.utils.data.DataLoader`完成对数据集的封装。

```python
size= 256
bs = 64 # batch_size

train_loader = DataLoader(AtlasDataset(train_df, TRAIN, size), batch_size=bs, shuffle=True, num_workers=2)
valid_loader = DataLoader(AtlasDataset(valid_df, TRAIN, size), batch_size=bs, shuffle=True, num_workers=2)
test_loader  = DataLoader(AtlasDataset(sub_df, TEST, size, False), batch_size=bs, shuffle=False, num_workers=2)
```



